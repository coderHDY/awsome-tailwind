{
  "home": {
    "title": "ç„¡æ–™AIã‚¢ãƒ¼ãƒˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼šã‚ªãƒ¼ãƒ«ã‚¤ãƒ³ãƒ¯ãƒ³AIã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ  | ArtAny AI",
    "description": "ArtAny AIï¼šAIãƒ‘ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ï¼†ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ | é©šãã¹ãç”»åƒã€å‹•ç”»ã€ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã‚’ç„¡æ–™ã§ç”Ÿæˆ | ã‚¹ãƒãƒ¼ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç™ºè¦‹ã—ã€ã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å…±æœ‰",
    "keywords": "ç„¡æ–™AIå‹•ç”»ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã€ç„¡æ–™AIå‹•ç”»ãƒ„ãƒ¼ãƒ«ã€AIå‹•ç”»ã€ç„¡æ–™ç”»åƒã‹ã‚‰å‹•ç”»ã€ç„¡æ–™ç”»åƒã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã€ãƒ‡ã‚¸ã‚¿ãƒ«ãƒ’ãƒ¥ãƒ¼ãƒãƒ³"
  },
  "Header": {
    "text2image": "ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒ",
    "aiVideo": "AIå‹•ç”»",
    "text2video": "ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å‹•ç”»",
    "image2video": "ç”»åƒã‹ã‚‰å‹•ç”»",
    "wanvace": "Wan Vace",
    "videoEffects": "AIå‹•ç”»ã‚¨ãƒ•ã‚§ã‚¯ãƒˆ",
    "veo3": "Veo3",
    "aiImage": "AIç”»åƒ",
    "aiImageGenerator": "AIç”»åƒã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼",
    "flux1Kontext": "Flux1 Kontext",
    "aiTools": "AIãƒ„ãƒ¼ãƒ«",
    "promptGenerator": "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼",
    "explore": "æ¢ç´¢",
    "history": "å±¥æ­´",
    "pricing": "æ–™é‡‘",
    "inspiration": "ã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³",
    "about": "æ¦‚è¦"
  },
  "Hero": {
    "h1-up": "ã‚‚ã†é€€å±ˆãªã‚¹ãƒˆãƒƒã‚¯ç”»åƒã¯å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ­ãƒœãƒƒãƒˆãŒè‡³ã‚‹æ‰€ã§æä¾›ã™ã‚‹æœ€é«˜ã®ç„¡æ–™ã‚¹ãƒˆãƒƒã‚¯å†™çœŸã‚’ãŠæ¥½ã—ã¿ãã ã•ã„",
    "h1": "ãƒ—ãƒ¬ãƒŸã‚¢ãƒ å“è³ªã®ã‚¢ã‚»ãƒƒãƒˆã‚’å‚™ãˆãŸã‚ªãƒ¼ãƒ«ã‚¤ãƒ³ãƒ¯ãƒ³AIã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ",
    "search": "AIç”Ÿæˆç”»åƒã‚’æ¤œç´¢...",
    "searchButton": "æ¤œç´¢",
    "table-1": "AIç”»åƒã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼",
    "table-1-description": "è¨€è‘‰ã‹ã‚‰ç”»åƒã¸",
    "table-2": "ç”»åƒã‹ã‚‰å‹•ç”»",
    "table-2-description": "å‹•ç”»ã‚’ç”Ÿæˆ",
    "table-3": "ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å‹•ç”»",
    "table-3-description": "è¨€è‘‰ãŒä»Šã€æ˜ ç”»ã«ãªã‚‹ï¼",
    "table-4": "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼",
    "table-4-description": "AIãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ˜ãƒ«ãƒ‘ãƒ¼",
    "value-1": "AIã¨ç·¨é›†ãƒ„ãƒ¼ãƒ«ã‹ã‚‰ã‚¹ãƒˆãƒƒã‚¯ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¾ã§ã€ã™ã¹ã¦ã‚’ã‚«ãƒãƒ¼ï¼",
    "value-1-button": "ãƒ—ãƒ©ãƒ³ã‚’å–å¾—",
    "h2-1": "ã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å¾—ã‚‹",
    "h2-1-description": "ArtAny AIã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆãŒä½œæˆã—ãŸä½•åƒã‚‚ã®ç´ æ™´ã‚‰ã—ã„ç”»åƒã‚’ç™ºè¦‹",
    "h2-2": "ArtAny AIã‚¢ãƒ¼ãƒˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£",
    "h2-2-description": "ä¸–ç•Œä¸­ã®ä½•ç™¾ä¸‡ã‚‚ã®AIã‚¢ãƒ¼ãƒˆæ„›å¥½å®¶ã¨ä¸€ç·’ã«ã€ãƒˆãƒ¬ãƒ³ãƒ‰ã®AIç”Ÿæˆç”»åƒã€é­…åŠ›çš„ãªAIå‹•ç”»ã€æœ€å…ˆç«¯ã®AIã‚¢ãƒ¼ãƒˆã‚¹ã‚¿ã‚¤ãƒ«ã‚’æ¢ç´¢ã—ã€ã„ã„ã­ã‚„ã‚³ãƒ¡ãƒ³ãƒˆã‚’å…±æœ‰ã—ã¾ã—ã‚‡ã†ã€‚",
    "h2-2-button-1": "ä½œæˆã‚’é–‹å§‹",
    "h2-2-button-2": "ã•ã‚‰ã«æ¢ç´¢",
    "h2-3": "ã‚¯ãƒªã‚¨ã‚¤ã‚¿ãƒ¼ã®ãŠæ°—ã«å…¥ã‚Š",
    "h2-3-description": "ç¾åœ¨ArtAny AIã‚¢ãƒ¼ãƒˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã§æœ€ã‚‚æ³¨ç›®ã‚’é›†ã‚ã¦ã„ã‚‹ã‚‚ã®ã‚’ãƒã‚§ãƒƒã‚¯",
    "h2-4": "ãƒ‘ãƒ¯ãƒ•ãƒ«ãªãƒ„ãƒ¼ãƒ«ï¼šã‚ã‚‰ã‚†ã‚‹ã‚¹ã‚­ãƒ«ãƒ¬ãƒ™ãƒ«ã®ã‚¯ãƒªã‚¨ã‚¤ã‚¿ãƒ¼å‘ã‘",
    "h2-5": "AIã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã®ä½¿ç”¨",
    "h2-5-description": "ã‚ãªãŸã®ã‚¢ãƒ¼ãƒˆã®ãŸã‚ã®ç„¡æ–™ãƒ„ãƒ¼ãƒ«",
    "h2-5-h3-1": "æ´»æ°—ã‚ã‚‹AIã‚¢ãƒ¼ãƒˆã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å‚åŠ ",
    "h2-5-h3-1-description": "æ¯æœˆä½•ç™¾ä¸‡ã‚‚ã®äººã€…ãŒArtAny AIã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ã€AIã‚¢ãƒ¼ãƒˆã‚’ä½œæˆã€å…±æœ‰ã€è­°è«–ã—ã¦ã„ã¾ã™ã€‚ç°¡å˜ãªæ‰‹é †ã§ã€å‹é”ã¨å…±æœ‰ã§ãã‚‹AIç”»åƒã‚„ã‚¤ãƒ©ã‚¹ãƒˆã‚’ä½œæˆã§ãã¾ã™ã€‚",
    "h2-5-h3-2": "å‹é”ã¨ä¸€ç·’ã«ä½œæˆ",
    "h2-5-h3-2-description": "å‹é”ã¨ãƒãƒ£ãƒƒãƒˆãƒ«ãƒ¼ãƒ ã‚’é–‹å§‹ã¾ãŸã¯å‚åŠ ã—ã€AIã‚¢ãƒ¼ãƒˆã§ã‚³ãƒ©ãƒœãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€ã‚¸ãƒ£ãƒ ã‚»ãƒƒã‚·ãƒ§ãƒ³ã€ã¾ãŸã¯ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ã«éã”ã—ã¾ã—ã‚‡ã†ã€‚",
    "h2-5-h3-3": "å…¬å¼ãƒ‡ã‚¤ãƒªãƒ¼AIã‚¢ãƒ¼ãƒˆãƒãƒ£ãƒ¬ãƒ³ã‚¸",
    "h2-5-h3-3-description": "ã‚ãªãŸã®å‰µé€ æ€§ã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¹ã‚­ãƒ«ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã—ã‚‡ã†ã€‚æ¯æ—¥ä½•åƒã‚‚ã®äººã€…ãŒå‚åŠ ã—ã€ãŠäº’ã„ã®å†™çœŸä½œå“ã«æŠ•ç¥¨ã—ã¦ã„ã¾ã™ã€‚",
    "h2-5-h3-4": "ç„¡æ–™ã§ä½¿ç”¨å¯èƒ½",
    "h2-5-h3-4-description": "ç„¡åˆ¶é™ã®åŸºæœ¬Stable Diffusionç”Ÿæˆã«åŠ ãˆã€ã‚ˆã‚Šå¼·åŠ›ãªAIã‚¢ãƒ¼ãƒˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ãƒ¢ãƒ‡ãƒ«ã¨è¨­å®šã«ä½¿ç”¨ã§ãã‚‹æ¯æ—¥ã®ç„¡æ–™ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã€‚",
    "h2-5-h3-5": "ä»–ã®ã©ã“ã‚ˆã‚Šã‚‚å¤šã„AIã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ",
    "h2-5-h3-5-description": "Fluxã€Stable Diffusionã€DALL-E 3ã€Ideogramã€SDXLã€ä½•åƒã‚‚ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°AIãƒ¢ãƒ‡ãƒ«ã€ã•ã‚‰ã«CLIP-Guided Diffusionã€VQGAN+CLIPã€Neural Style Transferã‹ã‚‰é¸æŠã§ãã¾ã™ã€‚",
    "h2-5-h3-6": "ã‚¦ã‚§ãƒ–ã¨ãƒ¢ãƒã‚¤ãƒ«ã®AIã‚¢ãƒ¼ãƒˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼",
    "h2-5-h3-6-description": "ãƒ©ãƒƒãƒ—ãƒˆãƒƒãƒ—ã€ã‚¿ãƒ–ãƒ¬ãƒƒãƒˆã€ãƒ¢ãƒã‚¤ãƒ«ã‹ã‚‰é«˜å“è³ªãªAIç”Ÿæˆç”»åƒã‚’ä½œæˆã—ã€ä»»æ„ã®ãƒ‡ãƒã‚¤ã‚¹ã‹ã‚‰ç”»åƒã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€‚",
    "h2-5-button-1": "ä½œæˆã‚’é–‹å§‹",
    "h2-6": "AIã‚¢ãƒ¼ãƒˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼FAQ",
    "h2-6-description": "AIã‚¢ãƒ¼ãƒˆã¨ArtAnyã«ã¤ã„ã¦ã‚ˆãã‚ã‚‹è³ªå•",
    "h2-6-h3-1": "ArtAny AIã‚¢ãƒ¼ãƒˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã¯ã©ã®ã‚ˆã†ã«æ©Ÿèƒ½ã—ã¾ã™ã‹ï¼Ÿ",
    "h2-6-h3-1-answer": "ArtAnyã¯ã‚¢ãƒ¼ãƒˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã§ã™ãŒã€ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã®ã¯ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã§ã™ã€‚ä½•ç™¾ä¸‡ã‚‚ã®ä»–ã®AIã‚¢ãƒ¼ãƒˆæ„›å¥½å®¶ã¨ä¸€ç·’ã«ã€ä½œå“ã‚’å…¬é–‹ã—ã€ä»–ã®ä½œå“ã«ã„ã„ã­ã‚„ã‚³ãƒ¡ãƒ³ãƒˆã‚’ä»˜ã‘ã€AIã‚¢ãƒ¼ãƒˆãƒãƒ£ãƒƒãƒˆãƒ«ãƒ¼ãƒ ã§äº¤æµã—ã€ã‚¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã‚³ãƒ³ãƒ†ã‚¹ãƒˆã‚„ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã«å‚åŠ ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ - ã™ã¹ã¦ArtAnyã‚’é›¢ã‚Œã‚‹ã“ã¨ãªãã€‚",
    "h2-6-h3-2": "ArtAnyã®ä½¿ç”¨ã«ã¯è²»ç”¨ãŒã‹ã‹ã‚Šã¾ã™ã‹ï¼Ÿ",
    "h2-6-h3-2-answer": "åŸºæœ¬å“è³ªã®AIã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼ˆç”»åƒã¨çŸ­ã„å‹•ç”»ï¼‰ã¯ç„¡æ–™ã§ç”Ÿæˆã§ãã¾ã™ã€‚ã‚ˆã‚Šé«˜ã„è§£åƒåº¦ã€ã‚ˆã‚Šé•·ã„æ™‚é–“ã€ã¾ãŸã¯ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªå‡ºåŠ›ã«ã¯ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆãŒå¿…è¦ã§ã™ã€‚æ¯æ—¥ç„¡æ–™ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆãŒæä¾›ã•ã‚Œã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£å‚åŠ ã‚’é€šã˜ã¦ã•ã‚‰ã«ç²å¾—ã§ãã¾ã™ï¼å°åˆ·ã‚„ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªä½œå“ãªã©ã®ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã‚µãƒ¼ãƒ“ã‚¹ã®ã¿æ”¯æ‰•ã„ãŒå¿…è¦ã§ã™ã€‚",
    "h2-6-h3-3": "ArtAnyã«ã¯ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªæ©Ÿèƒ½ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
    "h2-6-h3-3-answer": "ã¯ã„ï¼ArtAnyã¯ä»–ã®ã©ã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚ˆã‚Šã‚‚å¤šãã®AIã‚¢ãƒ¼ãƒˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’æŒã¡ã€ã•ã‚‰ã«å¤šãã®ã‚½ãƒ¼ã‚·ãƒ£ãƒ«æ©Ÿèƒ½ã‚‚å‚™ãˆã¦ãŠã‚Šã€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆä¸Šã§æœ€ã‚‚æ´»æ°—ã®ã‚ã‚‹AIã‚¢ãƒ¼ãƒˆã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚",
    "h2-6-h3-4": "ArtAnyã«ã¯ã©ã®ã‚ˆã†ãªAIãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
    "h2-6-h3-4-answer": "ArtAnyã¯ä»–ã®ã©ã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚ˆã‚Šã‚‚å¤šãã®AIã‚¢ãƒ¼ãƒˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚Fluxã€Stable Diffusionã€Dall-e 3ã€Ideogramã€Google Imagenã€ã•ã‚‰ã«LUMA Dream Machineã‚„Stable Video Diffusionãªã©ã®å‹•ç”»ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã€ä»Šå¾Œã•ã‚‰ã«è¿½åŠ äºˆå®šã§ã™ï¼"
  },
  "Pricing": {
    "title": "ArtAny AI æ–™é‡‘ - AIå‹•ç”»ãƒ»ç”»åƒç”Ÿæˆ",
    "description": "ArtAnyã®æ–™é‡‘ãƒ—ãƒ©ãƒ³ã‚’æ¢ç´¢ã—ã¦ãã ã•ã„ã€‚AIå‹•ç”»ãƒ»ç”»åƒç”Ÿæˆãƒ„ãƒ¼ãƒ«ã§ã€ã‚ãªãŸã®ãƒ‹ãƒ¼ã‚ºã«æœ€é©ãªãƒ—ãƒ©ãƒ³ã‚’é¸æŠã—ã€AIã§ç´ æ™´ã‚‰ã—ã„ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚’ä½œæˆã—å§‹ã‚ã¾ã—ã‚‡ã†ï¼",
    "headline": "ArtAny AI æ–™é‡‘ãƒ—ãƒ©ãƒ³",
    "subheadline": "ã‚ãªãŸã®ãƒ‹ãƒ¼ã‚ºã«æœ€é©ãªãƒ—ãƒ©ãƒ³ã‚’é¸æŠã—ã€AIã§ç´ æ™´ã‚‰ã—ã„ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚’ä½œæˆã—å§‹ã‚ã¾ã—ã‚‡ã†ï¼",
    "creationLimits": "æœ€å¤§ {videoCount} å‹•ç”»ã¾ãŸã¯ {imageCount} ç”»åƒ",
    "creditsPerPeriod": "{period}ã‚ãŸã‚Š {creditCount} ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆ",
    "month": "æœˆ",
    "year": "å¹´",
    "plans": {
      "plan2": {
        "name": "ã‚¹ã‚¿ãƒ¼ã‚¿ãƒ¼ãƒ—ãƒ©ãƒ³",
        "description": "å°ã•ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«æœ€é©",
        "features": {
          "feature1": "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ç„¡æ–™",
          "feature2": "ã™ã¹ã¦ã®AIãƒ¢ãƒ‡ãƒ«ã«ã‚¢ã‚¯ã‚»ã‚¹",
          "feature3": "å‹•ç”»ã®ç„¡åˆ¶é™ä½¿ç”¨ ğŸ”¥",
          "feature4": "å¹´é–“æ–™é‡‘ã§ä¸€åº¦ã«ã™ã¹ã¦ã®ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚’å–å¾—",
          "feature5": "å‹•ç”»å±¥æ­´",
          "feature6": "å•†ç”¨ãƒ©ã‚¤ã‚»ãƒ³ã‚¹",
          "feature7": "ç„¡åˆ¶é™ã®é«˜é€Ÿãƒ¢ãƒ‡ãƒ«",
          "feature8": "åºƒå‘Šãªã—",
          "feature9": "ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã¯ç¹°ã‚Šè¶Šã•ã‚Œã€æœŸé™åˆ‡ã‚Œã«ãªã‚Šã¾ã›ã‚“"
        }
      },
      "plan3": {
        "name": "ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ãƒ—ãƒ©ãƒ³",
        "description": "ã‚ˆã‚Šå¤šãã®æ©Ÿèƒ½ãŒå¿…è¦",
        "features": {
          "feature1": "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ç„¡æ–™",
          "feature2": "ã™ã¹ã¦ã®AIãƒ¢ãƒ‡ãƒ«ã«ã‚¢ã‚¯ã‚»ã‚¹",
          "feature3": "å‹•ç”»ã®ç„¡åˆ¶é™ä½¿ç”¨ ğŸ”¥",
          "feature4": "å¹´é–“æ–™é‡‘ã§ä¸€åº¦ã«ã™ã¹ã¦ã®ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚’å–å¾—",
          "feature5": "å‹•ç”»å±¥æ­´",
          "feature6": "å•†ç”¨ãƒ©ã‚¤ã‚»ãƒ³ã‚¹",
          "feature7": "ç„¡åˆ¶é™ã®é«˜é€Ÿãƒ¢ãƒ‡ãƒ«",
          "feature8": "åºƒå‘Šãªã—",
          "feature9": "ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã¯ç¹°ã‚Šè¶Šã•ã‚Œã€æœŸé™åˆ‡ã‚Œã«ãªã‚Šã¾ã›ã‚“"
        }
      },
      "plan4": {
        "name": "ã‚¢ãƒ‰ãƒãƒ³ã‚¹ãƒ‰ãƒ—ãƒ©ãƒ³",
        "description": "ã‚ˆã‚Šå¤šãã®æ©Ÿèƒ½ãŒå¿…è¦",
        "features": {
          "feature1": "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ç„¡æ–™",
          "feature2": "ã™ã¹ã¦ã®AIãƒ¢ãƒ‡ãƒ«ã«ã‚¢ã‚¯ã‚»ã‚¹",
          "feature3": "å‹•ç”»ã®ç„¡åˆ¶é™ä½¿ç”¨ ğŸ”¥",
          "feature4": "å¹´é–“æ–™é‡‘ã§ä¸€åº¦ã«ã™ã¹ã¦ã®ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚’å–å¾—",
          "feature5": "å‹•ç”»å±¥æ­´",
          "feature6": "å•†ç”¨ãƒ©ã‚¤ã‚»ãƒ³ã‚¹",
          "feature7": "ç„¡åˆ¶é™ã®é«˜é€Ÿãƒ¢ãƒ‡ãƒ«",
          "feature8": "åºƒå‘Šãªã—",
          "feature9": "ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã¯ç¹°ã‚Šè¶Šã•ã‚Œã€æœŸé™åˆ‡ã‚Œã«ãªã‚Šã¾ã›ã‚“"
        }
      }
    }
  },
  "refundPolicy": {
    "title": "Refund Policy",
    "description": "At ArtAny AI, we are committed to providing an exceptional experience for our users. We understand that circumstances may change, and you may need to request a refund. Please read our refund policy carefully before making a purchase.",
    "refundEligibility": {
      "title": "Refund Eligibility",
      "description": "Time Limit: ",
      "timeLimit": "Refund requests must be made within 3 days of your purchase. After this period, we will be unable to process any refund requests.",
      "creditUsage": "Credit Usage: ",
      "creditUsageDescription": "If you have used more than 100 credits, regardless of the purchase date, you will no longer be eligible for a refund."
    },
    "howToRequest": {
      "title": "How to Request a Refund",
      "description": "If you meet the above eligibility criteria and wish to request a refund, please follow these steps:",
      "contactUs": "Contact Us: ",
      "contactUsDescription": "Reach out to our support team via email at ",
      "contactUsLink": "help@artany.ai",
      "provideDetails": "Provide Details: ",
      "provideDetailsDescription": "Include your account information, order number, purchase date, and the reason for your refund request in the email.",
      "submitOnTime": "Submit on Time: ",
      "submitOnTimeDescription": "Ensure your refund request is submitted within 3 days of purchase."
    },
    "refundProcessing": {
      "title": "Refund Processing",
      "description": "Once we receive your refund request, we will review it and notify you of the result as soon as possible. If approved, the refund will be processed through your original payment method."
    },
    "policyChanges": {
      "title": "Policy Changes",
      "description": "We reserve the right to update the refund policy at any time. Any changes will be posted on this page, and we recommend checking regularly for the latest information."
    }
  },
  "text2video": {
    "title": "ã‚¢ãƒ¼ãƒˆå‹•ç”»ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼šãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å‹•ç”»ã¸ | ArtAny AI Video",
    "description": "Art AI ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å‹•ç”»ã¸ â€“ AIã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ—ãƒ­å“è³ªã®å‹•ç”»ã«ç¬æ™‚ã«å¤‰æ›ã€‚ã‚¹ãƒãƒ¼ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ¡ãƒ‡ã‚£ã‚¢ã‚„ãƒ“ã‚¸ãƒã‚¹ã«æœ€é©ãªã‚¯ãƒªãƒƒãƒ—ã‚’ä½œæˆã€‚ArtAny AI"
  },
  "wan-vace": {
    "title": "Wan 2.1 VACEï¼šã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹å‹•ç”»ç”Ÿæˆãƒ¢ãƒ‡ãƒ« | Wan VACE",
    "description": "Wan AI VACEã¯ã€é–‹å§‹ãƒ•ãƒ¬ãƒ¼ãƒ ã¨çµ‚äº†ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰HDå‹•ç”»ã‚’ç”Ÿæˆã™ã‚‹14Bã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã§ã€ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãŠã‚ˆã³å•†ç”¨åˆ©ç”¨ã«æœ€é©ã§ã™ã€‚Seedance AI Video Generation"
  },
  "wan-ai": {
    "title": "Wan AI Video Generation Model (Wan 2.1)| ArtAny AI",
    "description": "ArtAny AI integrates Wan AI video models, featuring Wan 2.1! Generate anime, realistic & 3D videos effortlessly. Perfect for creators and businesses. "
  },
  "image2video": {
    "title": "Art AI ç”»åƒã‹ã‚‰å‹•ç”»ã¸ã€ç”»åƒã‹ã‚‰ã®å‹•ç”»ç”Ÿæˆ | ArtAny",
    "description": "ArtAny AIã®ç”»åƒã‹ã‚‰å‹•ç”»ã¸ã®ãƒ„ãƒ¼ãƒ«ã¯ã€AIã‚’ä½¿ç”¨ã—ã¦ç”»åƒã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰å‹•ç”»ã‚’ä½œæˆã—ã¾ã™ã€‚ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã€ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ¡ãƒ‡ã‚£ã‚¢ã€å€‹äººãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«æœ€é©ã€‚ä»Šã™ããŠè©¦ã—ãã ã•ã„ï¼"
  },
  "videoEffects": {
    "title": "å‹•ç”»ç”¨AIã‚¨ãƒ•ã‚§ã‚¯ãƒˆ - ç„¡æ–™AIãƒ“ãƒ‡ã‚ªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ | ArtAny AI",
    "description": "ArtAny AIã§40ä»¥ä¸Šã®ç„¡æ–™AIå‹•ç”»ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç™ºè¦‹ï¼æœ€å…ˆç«¯ã®AIæŠ€è¡“ã‚’ä½¿ç”¨ã—ã¦ã€é­…åŠ›çš„ãªå‹•ç”»ã‚’ç°¡å˜ã«ä½œæˆã€‚ä»Šã™ããŠè©¦ã—ãã ã•ã„ï¼"
  },
  "veo3": {
    "title": "Google Veo3 AIå‹•ç”»ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼šãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å‹•ç”»ã¸ | ArtAny AI",
    "description": "Veo 3ã‚’ä½¿ç”¨ã—ã¦ã€éŸ³å£°ãŒåŒæœŸã•ã‚ŒãŸç´ æ™´ã‚‰ã—ã„AIå‹•ç”»ã‚’ä½œæˆã€‚åŠ¹æœéŸ³ã€ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã€ç’°å¢ƒéŸ³ã‚’è¿½åŠ ã™ã‚‹æœ€æ–°ã®AIå‹•ç”»ç”Ÿæˆãƒ„ãƒ¼ãƒ«ã€‚"
  },
  "models": {
    "wan-ai": {
      "title": "Wan 2.1: Leading AI Video Generation Model (Wanx 2.1)|Wan AI",
      "description": "Wan 2.1 (Alibaba WanX AI) an AI creative platform,enables text-to-image, image editing, text-to-video, video-to-video and image-to-video creation powered by AI.",
      "h1": "Wan 2.1 (Wanx 2.1) by Alibaba Wan AI",
      "h1-description": "Wan AI is an advanced and powerful visual generation model developed by Tongyi Lab. It can generate videos based on text, images and other control signals. The Wan 2.1 series models are now fully open-source.",
      "h2-1": "Overview of Wan AI",
      "h2-1-h3-1": "SOTA Performance",
      "h2-1-h3-1-description": "Wan 2.1 consistently outperforms existing open-source models and state-of-the-art commercial solutions across multiple benchmarks.",
      "h2-1-h3-2": "Supports Consumer-grade GPUs",
      "h2-1-h3-2-description": "The T2V-1.3B model requires only 8.19 GB VRAM, making it compatible with almost all consumer-grade GPUs. It can generate a 5-second 480P video on an RTX 4090 in about 4 minutes (without optimization techniques like quantization). Its performance is even comparable to some closed-source models.",
      "h2-1-h3-3": "Multiple tasks",
      "h2-1-h3-3-description": "Wan 2.1 excels in Text-to-Video, Image-to-Video, Video Editing, Text-to-Image, and Video-to-Audio, advancing the field of video generation.",
      "h2-1-h3-4": "Visual Text Generation",
      "h2-1-h3-4-description": "Wan 2.1 is the first video model capable of generating both Chinese and English text, featuring robust text generation that enhances its practical applications.",
      "h2-1-h3-5": "Powerful Video VAE of Wan AI",
      "h2-1-h3-5-description": "Wan-VAE delivers exceptional efficiency and performance, encoding and decoding 1080P videos of any length while preserving temporal information, making it an ideal foundation for video and image generation.",
      "h2-2": "Features of Wan AI",
      "h2-2-h3-1": "Complex Motions by Wan AI 2.1",
      "h2-2-h3-1-description": "Excels at generating realistic videos featuring extensive body movements, complex rotations, dynamic scene transitions, and fluid camera motions.",
      "h2-2-h3-2": "Physical Simulation by Wan AI 2.1",
      "h2-2-h3-2-description": "Generates videos that accurately simulate real-world physics and realistic object interactions.",
      "h2-2-h3-3": "Cinematic Quality by Wan AI 2.1",
      "h2-2-h3-3-description": "Offers movie-like visuals with rich textures and a variety of stylized effects.",
      "h2-2-h3-4": "Controllable Editing by Wan AI 2.1",
      "h2-2-h3-4-description": "Features a universal editing model for precise edits using image or video references.",
      "h2-2-h3-5": "Visual Text Generation by Wan AI 2.1",
      "h2-2-h3-5-description": "Creates text and dynamic text effects in videos directly from text prompts.",
      "h2-3": "Product Features",
      "h2-3-description": "Through our product, you can seamlessly leverage our models with a user-friendly experience to access inspiring video content.",
      "h2-3-h3-1": "Text to Video",
      "h2-3-h3-2": "Image to Video",
      "h2-3-h3-3": "Start and End Frames",
      "h2-4": "Wan AI 2.1 Open Source",
      "h2-4-description": "In this repo, we release the code and weights for the Wan 2.1, a comprehensive and open suite of video foundation models designed to push the boundaries of video generation.",
      "h2-4-h3-1": "Wan2.1-I2V-14B",
      "h2-4-h3-1-720P": "https://huggingface.co/Wan-AI/Wan2.1-I2V-14B-720P?spm=5176.28735610.0.0.568be41ehS0jcL&file=Wan2.1-I2V-14B-720P",
      "h2-4-h3-1-480P": "https://huggingface.co/Wan-AI/Wan2.1-I2V-14B-480P?spm=5176.28735610.0.0.568be41ehS0jcL&file=Wan2.1-I2V-14B-480P",
      "h2-4-h3-1-description": "The I2V-14B model outperforms leading closed-source models as well as all existing open-source models, achieving SOTA performance. It is capable of generating videos that demonstrate complex visual scenes and motion patterns based on input text and images, including both 480P and 720P resolution models.",
      "h2-4-h3-2": "Wan2.1-T2V-14B",
      "h2-4-h3-2-720P": "https://huggingface.co/Wan-AI/Wan2.1-T2V-14B?spm=5176.28735610.0.0.568be41ehS0jcL&file=Wan2.1-T2V-14B",
      "h2-4-h3-2-description": "The T2V-14B model sets a new SOTA performance among both open-source and closed-source models, showcasing its ability to generate high-quality visuals with substantial motion dynamics. It is also the only video model capable of producing both Chinese and English text and supports video generation at both 480P and 720P resolutions.",
      "h2-4-h3-3": "Wan2.1-T2V-1.3B",
      "h2-4-h3-3-480P": "https://huggingface.co/Wan-AI/Wan2.1-T2V-1.3B?spm=5176.28735610.0.0.568be41ehS0jcL&file=Wan2.1-T2V-1.3B",
      "h2-4-h3-3-description": "The T2V-1.3B model supports video generation on almost all consumer-grade GPUs, requiring only 8.19 GB of BRAM to produce a 5-second 480P video, with an output time of just 4 minutes on an RTX 4090 GPU. Through pre-training and distillation processes, it surpasses larger open-source models and achieves performance even comparable to some advanced closed-source models.",
      "h2-4-h3-4": "Wan2.1-FLF2V-14B-720P",
      "h2-4-h3-4-720P": "https://huggingface.co/Wan-AI/Wan2.1-FLF2V-14B-720P#run-first-last-frame-to-video-generation",
      "h2-4-h3-4-description": "Wan 2.1 First-Last-Frame-to-Video (FLF2V) is an AI-based video generation technology that synthesizes intermediate frames between a given start and end frame to produce smooth videos. It leverages a 14B-parameter model, supports multi-GPU accelerated inference, and offers pretrained checkpoints with a Gradio demo for interactive testing. Applications include video inpainting, animation production, and more.",
      "h2-5": "Frequently Asked Questions",
      "h2-5-h3-1": "What is Wan 2.1 by Wan AI and how does it work?",
      "h2-5-h3-1-description": "Wan 2.1 by Wan AI is Alibaba Cloud's state-of-the-art video generation model that transforms text descriptions into stunning, high-quality videos. Leveraging advanced technologies like Variational Autoencoders (VAE) and Diffusion Transformers (DiT), it ensures realistic visuals, smooth transitions, and accurate physics for a truly immersive experience.",
      "h2-5-h3-2": "Do I need technical expertise to use Wan 2.1 by Wan AI?",
      "h2-5-h3-2-description": "Wan 2.1 by Wan AI is designed with simplicity in mind. Its intuitive interface allows anyone to create professional-quality videos effortlessly, even without advanced technical skills. Whether you're a beginner or a pro, you'll find the platform easy to navigate and use.",
      "h2-5-h3-3": "What types of videos can I create with Wan 2.1 by Wan AI?",
      "h2-5-h3-3-description": "Wan 2.1 by Wan AI is versatile and capable of generating a wide range of video content. From dynamic scenes like dancing and sports to educational tutorials and historical video restoration, it empowers you to bring your creative vision to life.",
      "h2-5-h3-4": "How long does it take to generate a video?",
      "h2-5-h3-4-description": "The video generation time depends on the complexity and length of your project. For faster results, the Pro version offers accelerated processing speeds, making it ideal for time-sensitive tasks.",
      "h2-5-h3-5": "Can I customize the video output?",
      "h2-5-h3-5-description": "Absolutely! Wan 2.1 by Wan AI provides extensive customization options, allowing you to adjust resolution, frame rate, movement complexity, and more. Tailor your videos to meet your specific needs and preferences.",
      "h2-5-h3-6": "What input formats does Wan 2.1 AI by Wan AI support for video generation?",
      "h2-5-h3-6-description": "Wan 2.1 AI by Wan AI primarily supports text descriptions as input for video generation. You can provide detailed textual prompts describing the scene, actions, and desired visual effects. Additionally, it may support image inputs for enhanced context in future updates.",
      "h2-5-h3-7": "Can Wan 2.1 AI by Wan AI generate videos in multiple languages?",
      "h2-5-h3-7-description": "Yes, Wan 2.1 AI by Wan AI supports multilingual text inputs, allowing you to generate videos based on descriptions in various languages. However, the quality of output may vary depending on the language and the complexity of the description.",
      "h2-5-h3-8": "Is there a limit to the length of videos that Wan 2.1 by Wan AI can generate?",
      "h2-5-h3-8-description": "The length of generated videos depends on the subscription plan. The free version may have limitations on video duration, while the Pro version supports longer and more complex video generation. Specific limits can be found in the platform's documentation.",
      "h2-5-h3-9": "How does Wan 2.1 by Wan AI ensure the quality of generated videos?",
      "h2-5-h3-9-description": "Wan 2.1 AI by Wan AI leverages advanced technologies like Variational Autoencoders (VAE) and Diffusion Transformers (DiT) to ensure high-quality outputs. These technologies enable realistic visuals, smooth transitions, and accurate physics simulations.",
      "h2-5-h3-10": "How does Wan 2.1 by Wan AI handle complex scenes with multiple characters?",
      "h2-5-h3-10-description": "Wan 2.1 by Wan AI is designed to handle complex scenes with multiple characters by analyzing the relationships and interactions described in the text input. It uses advanced algorithms to ensure realistic positioning, movements, and interactions between characters."
    },
    "flux1": {
      "title": "ALL the Top-Tier AI Video Models in ONE Place | ArtAny AI",
      "description": "Create pro videos at low cost! ArtAny combines all AI video models - image-to-video, video-to-video, effects & images made easy. Use ArtAny AI video generator !"
    }
  },
  "imageGenerator": {
    "title": "ç„¡æ–™AIç”»åƒã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ | ã‚¢ãƒ¼ãƒˆç”»åƒ | ArtAny AI Image",
    "description": "ArtAny AI - äººæ°—ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸ100%ç„¡æ–™ï¼†ç„¡åˆ¶é™ã®AIç”»åƒã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼â€”ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§é«˜å“è³ªãªãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚’ä½œæˆï¼ | ArtAny AI"
  },
  "flux1Kontext": {
    "title": "Flux1 Kontext Pro, Max, ãƒãƒ«ãƒç”»åƒ â€“ ArtAny AIã§Flux1ã‚’è©¦ã™",
    "description": "Flux.1 Kontextã§ç°¡å˜ã«ãƒãƒ«ãƒç”»åƒãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆãƒ»ç·¨é›†ã€‚è¤‡é›‘ãªä½œæ¥­ã‚’ç°¡å˜ã«ï¼ArtAny AIã§Flux Proã€Maxï¼†Multiã‚’ä»Šã™ããŠè©¦ã—ãã ã•ã„ï¼"
  },
  "homeShow": {
    "title": "Free AI Video Prompt Generator - AI Image Prompt Generator",
    "description": "the best prompt generator for AI video and image generation, Wan AI, Flux1, Runway, Veo3, Kling AI, Seedance1.0, Google, ByteDance, ArtAny AI"
  },
  "explore": {
    "title": "AI Videos: Discover Free AI-generated Videos | ArtAny",
    "description": "Find high-quality videos generated by AI. Create stunning AI videos using the same template."
  },
  "prompt": {
    "SEO": {
      "title": "Free AI Video Prompt Generator - Perfect Prompts for AI Model",
      "description": "Free prompt tool for AI! Generate prompts for image-to-video,text-to-video & text-to-image.Perfect for Wan AI, Flux, Runway.Ideal for creators & developers.",
      "keywords": "AI Prompt Generator Tool"
    },
    "promptGenerator": {
      "name": "Video Prompt Generator",
      "description": "Select prompt formula",
      "viewTutorial": "View tutorial",
      "selectFormula": "Select formula",
      "formulas": {
        "basic": {
          "name": "Basic Formula",
          "description": "Suitable for new users trying AI video for the first time"
        },
        "advanced": {
          "name": "Advanced Formula",
          "description": "Suitable for users with some AI video experience"
        },
        "camera": {
          "name": "Camera Movement Formula",
          "description": "Suitable for users with specific camera movement requirements"
        },
        "transformation": {
          "name": "Transformation Formula",
          "description": "Suitable for users who need transformation effects"
        }
      },
      "selectOutputLanguage": "Select output language",
      "enterYourIdea": "Enter your idea",
      "enterYourIdeaDescription": "Describe the video content you want to generate...",
      "loginForFreeAccess": "Login for free access",
      "generatePrompt": "Generate Prompt",
      "generating": "Generating...",
      "resultName": "Generated Result",
      "copied": "Copied",
      "copy": "Copy",
      "generatingPrompt": "Generating prompt, please wait...",
      "resultDescription": "Enter your idea on the left and generate a prompt.",
      "exploreMore": "Explore more"
    },
    "title": "How to write and debug AI prompts",
    "description": "We provide a powerful free prompt generator that helps users generate high-quality prompts, making it easier to use Wan AI and other AI video generation tools.",
    "target": "Target audience",
    "feature": "Features",
    "example": "Example prompts",
    "optionalTargetType": "Optional target type",
    "notRecommended": "Not recommended",
    "recommended": "Recommended",
    "initialPrompt": "Initial prompt",
    "exampleCombination": "Example combination",
    "adjustedPrompt": "Adjusted prompt",
    "combination1": "Combination 1",
    "combination2": "Combination 2",
    "recommendedOperation": "Recommended operation",
    "section1": {
      "title": "How to use the prompt generator",
      "modes": {
        "basic": {
          "name": "Basic mode (Basic Formula)",
          "target": "New users trying AI video for the first time",
          "feature": "Provides simple and easy-to-understand prompt templates, suitable for quick start",
          "example": "Beach, sunset, waves"
        },
        "advanced": {
          "name": "Advanced mode (Advanced Formula)",
          "target": "Users with some AI video generation experience",
          "feature": "Supports more complex prompt combinations, generating more creative videos",
          "example": "Future city, flying car, neon lights"
        },
        "camera": {
          "name": "Camera movement mode (Camera Movement Formula)",
          "target": "Users with specific camera movement requirements",
          "feature": "Supports adding camera movement effects, such as panning, zooming, and rotating",
          "example": "Mountain range, sunrise, panning"
        },
        "transformation": {
          "name": "Transformation mode (Transformation Formula)",
          "target": "Users who need to generate transformation effects",
          "feature": "Supports generating transformation effects of objects or scenes, such as gradual change and fusion",
          "example": "Flower, bloom, transformation"
        }
      }
    },
    "section2": {
      "title": "How to write AI prompts",
      "tips": {
        "clearGoal": {
          "title": "Clear goal",
          "description": "Before writing AI prompts, clearly define the video content you want to generate. The clearer your goal, the better the generated video will be.",
          "example1": "Landscape video",
          "example2": "Character close-up",
          "example3": "Dynamic effect"
        },
        "simpleLanguage": {
          "title": "Use simple language",
          "description": "AI prompts should be concise and clear, avoiding complex sentences.",
          "badExample": "Generate a video of children playing in the park in the afternoon.",
          "goodExample": "Sunny afternoon, children, park, play"
        },
        "keywordCombination": {
          "title": "Keyword combination",
          "description": "Combine multiple keywords to generate more diverse video content.",
          "example": "Sunset, beach, waves, coconut tree"
        },
        "styleEmotion": {
          "title": "Add style or emotion",
          "description": "If you need a specific style or emotion, you can add related descriptions in the AI prompt.",
          "example": "Romantic, sunset, couple, walk"
        }
      }
    },
    "section3": {
      "title": "How to debug AI prompts",
      "tips": {
        "stepByStep": {
          "title": "Step by step",
          "description": "If the generated video is not satisfactory, you can adjust the AI prompt step by step.",
          "initialPrompt": "City, night view",
          "adjustedPrompt": "City, night view, light, traffic"
        },
        "testCombinations": {
          "title": "Test different combinations",
          "description": "Try different keyword combinations to find the best effect.",
          "combination1": "Forest, morning mist, sunshine",
          "combination2": "Forest, morning mist, bird song"
        },
        "reference": {
          "title": "Reference template",
          "description": "Reference our provided prompts and AI video templates, quick start.",
          "item1": "Browse template library",
          "item2": "Reference popular prompts",
          "item3": "Learn success cases",
          "link1": "View detailed tutorial",
          "link2": "View template samples"
        }
      }
    }
  },
  "Creator": {
    "title": "Portfolio",
    "description": "A collection of works by ArtAny creators.",
    "keywords": "ArtAny creators, ArtAny portfolio, ArtAny artworks, ArtAny creator works"
  }
}