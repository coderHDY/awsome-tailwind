{
  "home": {
    "title": "ë¬´ë£Œ AI ì•„íŠ¸ ìƒì„±ê¸°: ì˜¬ì¸ì› AI í¬ë¦¬ì—ì´í‹°ë¸Œ í”Œë«í¼ | ArtAny AI",
    "description": "ArtAny AI: AI ê¸°ë°˜ í¬ë¦¬ì—ì´í‹°ë¸Œ í”Œë«í¼ & ì»¤ë®¤ë‹ˆí‹° | ë†€ë¼ìš´ ì´ë¯¸ì§€, ë¹„ë””ì˜¤ & ë¦½ì‹±í¬ë¥¼ ë¬´ë£Œë¡œ ìƒì„± | ìŠ¤ë§ˆíŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ë°œê²¬í•˜ê³  ì˜ê°ì„ ê³µìœ í•˜ì„¸ìš”",
    "keywords": "ë¬´ë£Œ AI ë¹„ë””ì˜¤ ìƒì„±ê¸°, ë¬´ë£Œ AI ë¹„ë””ì˜¤ ë„êµ¬, AI ë¹„ë””ì˜¤, ë¬´ë£Œ ì´ë¯¸ì§€ì—ì„œ ë¹„ë””ì˜¤, ë¬´ë£Œ ì´ë¯¸ì§€ ìƒì„±ê¸°, ë””ì§€í„¸ íœ´ë¨¼"
  },
  "Header": {
    "text2image": "í…ìŠ¤íŠ¸ì—ì„œ ì´ë¯¸ì§€",
    "aiVideo": "AI ë¹„ë””ì˜¤",
    "text2video": "í…ìŠ¤íŠ¸ì—ì„œ ë¹„ë””ì˜¤",
    "image2video": "ì´ë¯¸ì§€ì—ì„œ ë¹„ë””ì˜¤",
    "wanvace": "Wan Vace",
    "videoEffects": "AI ë¹„ë””ì˜¤ íš¨ê³¼",
    "veo3": "Veo3",
    "aiImage": "AI ì´ë¯¸ì§€",
    "aiImageGenerator": "AI ì´ë¯¸ì§€ ìƒì„±ê¸°",
    "flux1Kontext": "Flux1 Kontext",
    "aiTools": "AI ë„êµ¬",
    "promptGenerator": "í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸°",
    "explore": "íƒìƒ‰",
    "history": "ê¸°ë¡",
    "pricing": "ê°€ê²©",
    "inspiration": "ì˜ê°",
    "about": "ì†Œê°œ"
  },
  "Hero": {
    "h1-up": "ë” ì´ìƒ ì§€ë£¨í•œ ìŠ¤í†¡ ì´ë¯¸ì§€ëŠ” í•„ìš” ì—†ìŠµë‹ˆë‹¤. ë¡œë´‡ì´ ëª¨ë“  ê³³ì—ì„œ ì œê³µí•˜ëŠ” ìµœê³ ì˜ ë¬´ë£Œ ìŠ¤í†¡ ì‚¬ì§„ì„ ì¦ê¸°ì„¸ìš”",
    "h1": "í”„ë¦¬ë¯¸ì—„ í’ˆì§ˆì˜ ì—ì…‹ì„ ê°–ì¶˜ ì˜¬ì¸ì› AI í¬ë¦¬ì—ì´í‹°ë¸Œ í”Œë«í¼",
    "search": "AI ìƒì„± ì´ë¯¸ì§€ ê²€ìƒ‰...",
    "searchButton": "ê²€ìƒ‰",
    "table-1": "AI ì´ë¯¸ì§€ ìƒì„±ê¸°",
    "table-1-description": "ë‹¨ì–´ì—ì„œ ì´ë¯¸ì§€ë¡œ",
    "table-2": "ì´ë¯¸ì§€ì—ì„œ ë¹„ë””ì˜¤",
    "table-2-description": "ë¹„ë””ì˜¤ ìƒì„±",
    "table-3": "í…ìŠ¤íŠ¸ì—ì„œ ë¹„ë””ì˜¤",
    "table-3-description": "ë‹¨ì–´ê°€ ì´ì œ ì˜í™”ê°€ ë©ë‹ˆë‹¤!",
    "table-4": "í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸°",
    "table-4-description": "AI í”„ë¡¬í”„íŠ¸ ë„ìš°ë¯¸",
    "value-1": "AIì™€ í¸ì§‘ ë„êµ¬ë¶€í„° ìŠ¤í†¡ ì½˜í…ì¸ ê¹Œì§€, ëª¨ë“  ê²ƒì„ ì»¤ë²„!",
    "value-1-button": "í”Œëœ ì„ íƒí•˜ê¸°",
    "h2-1": "ì˜ê°ì„ ì–»ìœ¼ì„¸ìš”",
    "h2-1-description": "ArtAny AI ì•„í‹°ìŠ¤íŠ¸ë“¤ì´ ë§Œë“  ìˆ˜ì²œ ê°œì˜ ë†€ë¼ìš´ ì´ë¯¸ì§€ë¥¼ ë°œê²¬í•˜ì„¸ìš”",
    "h2-2": "ArtAny AI ì•„íŠ¸ ìƒì„±ê¸° ì»¤ë®¤ë‹ˆí‹°",
    "h2-2-description": "ì „ ì„¸ê³„ ìˆ˜ë°±ë§Œ AI ì•„íŠ¸ ì• í˜¸ê°€ë“¤ê³¼ í•¨ê»˜ ìµœì‹  íŠ¸ë Œë“œì˜ AI ìƒì„± ì´ë¯¸ì§€, ë§¤ë ¥ì ì¸ AI ë¹„ë””ì˜¤, ìµœì²¨ë‹¨ AI ì•„íŠ¸ ìŠ¤íƒ€ì¼ì„ íƒìƒ‰í•˜ê³ , ì¢‹ì•„ìš”ë¥¼ ëˆ„ë¥´ê³ , ëŒ“ê¸€ì„ ë‹¬ì•„ë³´ì„¸ìš”.",
    "h2-2-button-1": "ìƒì„± ì‹œì‘í•˜ê¸°",
    "h2-2-button-2": "ë” íƒìƒ‰í•˜ê¸°",
    "h2-3": "í¬ë¦¬ì—ì´í„°ë“¤ì˜ ì¸ê¸°ì‘",
    "h2-3-description": "í˜„ì¬ ArtAny AI ì•„íŠ¸ ìƒì„±ê¸°ì—ì„œ ê°€ì¥ ì£¼ëª©ë°›ê³  ìˆëŠ” ì‘í’ˆì„ í™•ì¸í•˜ì„¸ìš”",
    "h2-4": "ê°•ë ¥í•œ ë„êµ¬: ëª¨ë“  ìˆ˜ì¤€ì˜ í¬ë¦¬ì—ì´í„°ë¥¼ ìœ„í•œ",
    "h2-5": "AI ìƒì„±ê¸° ì‚¬ìš©í•˜ê¸°",
    "h2-5-description": "ë‹¹ì‹ ì˜ ì˜ˆìˆ ì„ ìœ„í•œ ë¬´ë£Œ ë„êµ¬",
    "h2-5-h3-1": "í™œê¸°ì°¬ AI ì•„íŠ¸ ì»¤ë®¤ë‹ˆí‹°ì— ì°¸ì—¬í•˜ì„¸ìš”",
    "h2-5-h3-1-description": "ë§¤ì›” ìˆ˜ë°±ë§Œ ëª…ì˜ ì‚¬ëŒë“¤ì´ ArtAny AI ìƒì„±ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ AI ì•„íŠ¸ë¥¼ ë§Œë“¤ê³ , ê³µìœ í•˜ê³ , í† ë¡ í•©ë‹ˆë‹¤. ê°„ë‹¨í•œ ë‹¨ê³„ë¡œ ì¹œêµ¬ë“¤ê³¼ ê³µìœ í•  ìˆ˜ ìˆëŠ” AI ì´ë¯¸ì§€ì™€ ì¼ëŸ¬ìŠ¤íŠ¸ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    "h2-5-h3-2": "ì¹œêµ¬ë“¤ê³¼ í•¨ê»˜ ë§Œë“¤ê¸°",
    "h2-5-h3-2-description": "ì¹œêµ¬ë“¤ê³¼ ì±„íŒ…ë°©ì„ ì‹œì‘í•˜ê±°ë‚˜ ì°¸ì—¬í•˜ì—¬ AI ì•„íŠ¸ë¡œ í˜‘ì—…í•˜ê³ , ì¼ì„ í•˜ê±°ë‚˜, ì°½ì˜ì ì¸ ì‹œê°„ì„ ë³´ë‚´ì„¸ìš”.",
    "h2-5-h3-3": "ê³µì‹ ì¼ì¼ AI ì•„íŠ¸ ì±Œë¦°ì§€",
    "h2-5-h3-3-description": "ë‹¹ì‹ ì˜ ì°½ì˜ì„±ê³¼ í”„ë¡¬í”„íŒ… ê¸°ìˆ ì„ ì‹œí—˜í•´ë³´ì„¸ìš”. ë§¤ì¼ ìˆ˜ì²œ ëª…ì˜ ì‚¬ëŒë“¤ì´ ì„œë¡œì˜ ì‚¬ì§„ ì‘í’ˆì— íˆ¬í‘œí•˜ê³  ì°¸ì—¬í•©ë‹ˆë‹¤.",
    "h2-5-h3-4": "ë¬´ë£Œë¡œ ì‚¬ìš© ê°€ëŠ¥",
    "h2-5-h3-4-description": "ë¬´ì œí•œ ê¸°ë³¸ Stable Diffusion ìƒì„±ê³¼ í•¨ê»˜, ë” ê°•ë ¥í•œ AI ì•„íŠ¸ ìƒì„±ê¸° ëª¨ë¸ê³¼ ì„¤ì •ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì¼ì¼ ë¬´ë£Œ í¬ë ˆë”§ì„ ì œê³µí•©ë‹ˆë‹¤.",
    "h2-5-h3-5": "ë‹¤ë¥¸ ì–´ë””ë³´ë‹¤ ë§ì€ AI ì•Œê³ ë¦¬ì¦˜",
    "h2-5-h3-5-description": "Flux, Stable Diffusion, DALL-E 3, Ideogram, SDXL, ìˆ˜ì²œ ê°œì˜ ì»¤ë®¤ë‹ˆí‹° í•™ìŠµ AI ëª¨ë¸, ê·¸ë¦¬ê³  CLIP-Guided Diffusion, VQGAN+CLIP, Neural Style Transfer ì¤‘ì—ì„œ ì„ íƒí•˜ì„¸ìš”.",
    "h2-5-h3-6": "ì›¹ê³¼ ëª¨ë°”ì¼ AI ì•„íŠ¸ ìƒì„±ê¸°",
    "h2-5-h3-6-description": "ë…¸íŠ¸ë¶, íƒœë¸”ë¦¿ ë˜ëŠ” ëª¨ë°”ì¼ì—ì„œ ê³ í’ˆì§ˆ AI ìƒì„± ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ê³  ëª¨ë“  ê¸°ê¸°ì—ì„œ ì´ë¯¸ì§€ë¥¼ ê²€í† í•˜ì„¸ìš”.",
    "h2-5-button-1": "ìƒì„± ì‹œì‘í•˜ê¸°",
    "h2-6": "AI ì•„íŠ¸ ìƒì„±ê¸° FAQ",
    "h2-6-description": "AI ì•„íŠ¸ì™€ ArtAnyì— ëŒ€í•œ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸",
    "h2-6-h3-1": "ArtAny AI ì•„íŠ¸ ìƒì„±ê¸°ëŠ” ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜ìš”?",
    "h2-6-h3-1-answer": "ArtAnyëŠ” ì•„íŠ¸ ìƒì„±ê¸°ì´ì§€ë§Œ, ë…íŠ¹í•œ ì ì€ ì»¤ë®¤ë‹ˆí‹°ì…ë‹ˆë‹¤. ìˆ˜ë°±ë§Œ ëª…ì˜ ë‹¤ë¥¸ AI ì•„íŠ¸ ì• í˜¸ê°€ë“¤ê³¼ í•¨ê»˜ ì‘í’ˆì„ ê³µìœ í•˜ê³ , ë‹¤ë¥¸ ì‘í’ˆì— ì¢‹ì•„ìš”ì™€ ëŒ“ê¸€ì„ ë‹¬ê³ , AI ì•„íŠ¸ ì±„íŒ…ë°©ì—ì„œ êµë¥˜í•˜ë©°, ì‹¬ì§€ì–´ ì•„íŠ¸ì›Œí¬ ì½˜í…ŒìŠ¤íŠ¸ì™€ ì±Œë¦°ì§€ì—ë„ ì°¸ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ - ëª¨ë‘ ArtAnyë¥¼ ë– ë‚˜ì§€ ì•Šê³ ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
    "h2-6-h3-2": "ArtAny ì‚¬ìš©ì— ë¹„ìš©ì´ ë“œë‚˜ìš”?",
    "h2-6-h3-2-answer": "ê¸°ë³¸ í’ˆì§ˆì˜ AI ì½˜í…ì¸ (ì´ë¯¸ì§€ ë° ì§§ì€ ë¹„ë””ì˜¤)ëŠ” ë¬´ë£Œë¡œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë” ë†’ì€ í•´ìƒë„, ë” ê¸´ ì‹œê°„, ë˜ëŠ” ì „ë¬¸ì ì¸ ì¶œë ¥ì—ëŠ” í¬ë ˆë”§ì´ í•„ìš”í•©ë‹ˆë‹¤. ì¼ì¼ ë¬´ë£Œ í¬ë ˆë”§ì´ ì œê³µë˜ë©°, ì»¤ë®¤ë‹ˆí‹° ì°¸ì—¬ë¥¼ í†µí•´ ë” ë§ì´ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤! ì¸ì‡„ë‚˜ ì „ë¬¸ì ì¸ ì‘í’ˆê³¼ ê°™ì€ í”„ë¦¬ë¯¸ì—„ ì„œë¹„ìŠ¤ë§Œ ê²°ì œê°€ í•„ìš”í•©ë‹ˆë‹¤.",
    "h2-6-h3-3": "ArtAnyë§Œì˜ ë…íŠ¹í•œ ê¸°ëŠ¥ì´ ìˆë‚˜ìš”?",
    "h2-6-h3-3-answer": "ë„¤! ArtAnyëŠ” ë‹¤ë¥¸ ì–´ë–¤ í”Œë«í¼ë³´ë‹¤ ë” ë§ì€ AI ì•„íŠ¸ ìƒì„±ê¸° ëª¨ë¸ì„ ë³´ìœ í•˜ê³  ìˆìœ¼ë©°, ë” ë§ì€ ì†Œì…œ ê¸°ëŠ¥ë„ ê°–ì¶”ê³  ìˆì–´ ì¸í„°ë„·ì—ì„œ ê°€ì¥ í™œê¸°ì°¬ AI ì•„íŠ¸ ì»¤ë®¤ë‹ˆí‹°ë¥¼ ë§Œë“¤ì–´ëƒ…ë‹ˆë‹¤.",
    "h2-6-h3-4": "ArtAnyì—ëŠ” ì–´ë–¤ AI ëª¨ë¸ë“¤ì´ ìˆë‚˜ìš”?",
    "h2-6-h3-4-answer": "ArtAnyëŠ” ë‹¤ë¥¸ ì–´ë–¤ í”Œë«í¼ë³´ë‹¤ ë” ë§ì€ AI ì•„íŠ¸ ìƒì„±ê¸° ëª¨ë¸ì„ ì œê³µí•©ë‹ˆë‹¤. Flux, Stable Diffusion, Dall-e 3, Ideogram, Google Imagen, ê·¸ë¦¬ê³  LUMA Dream Machineê³¼ Stable Video Diffusion ê°™ì€ ë¹„ë””ì˜¤ ëª¨ë¸ë„ ìˆìœ¼ë©°, ì•ìœ¼ë¡œ ë” ë§ì´ ì¶”ê°€ë  ì˜ˆì •ì…ë‹ˆë‹¤!"
  },
  "Pricing": {
    "title": "ArtAny AI ê°€ê²© - AI ë¹„ë””ì˜¤ ë° ì´ë¯¸ì§€ ìƒì„±",
    "description": "ArtAnyì˜ ê°€ê²© í”Œëœì„ íƒìƒ‰í•˜ì„¸ìš”. AI ë¹„ë””ì˜¤ ë° ì´ë¯¸ì§€ ìƒì„± ë„êµ¬ë¡œ, ê·€í•˜ì˜ ìš”êµ¬ì— ê°€ì¥ ì í•©í•œ í”Œëœì„ ì„ íƒí•˜ê³  AIë¡œ ë†€ë¼ìš´ ë¹„ì£¼ì–¼ì„ ë§Œë“¤ê¸° ì‹œì‘í•˜ì„¸ìš”!",
    "headline": "ArtAny AI ê°€ê²© í”Œëœ",
    "subheadline": "ê·€í•˜ì˜ ìš”êµ¬ì— ê°€ì¥ ì í•©í•œ í”Œëœì„ ì„ íƒí•˜ê³  AIë¡œ ë†€ë¼ìš´ ë¹„ì£¼ì–¼ì„ ë§Œë“¤ê¸° ì‹œì‘í•˜ì„¸ìš”!",
    "creationLimits": "ìµœëŒ€ {videoCount}ê°œ ë¹„ë””ì˜¤ ë˜ëŠ” {imageCount}ê°œ ì´ë¯¸ì§€",
    "creditsPerPeriod": "{period}ë‹¹ {creditCount} í¬ë ˆë”§",
    "month": "ì›”",
    "year": "ë…„",
    "plans": {
      "plan2": {
        "name": "ìŠ¤íƒ€í„° í”Œëœ",
        "description": "ì†Œê·œëª¨ í”„ë¡œì íŠ¸ì— ì™„ë²½",
        "features": {
          "feature1": "í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸° ë¬´ë£Œ",
          "feature2": "ëª¨ë“  AI ëª¨ë¸ ì ‘ê·¼",
          "feature3": "ë¹„ë””ì˜¤ ë¬´ì œí•œ ì‚¬ìš© ğŸ”¥",
          "feature4": "ì—°ê°„ ìš”ê¸ˆìœ¼ë¡œ ëª¨ë“  í¬ë ˆë”§ì„ í•œ ë²ˆì— ë°›ê¸°",
          "feature5": "ë¹„ë””ì˜¤ íˆìŠ¤í† ë¦¬",
          "feature6": "ìƒì—…ìš© ë¼ì´ì„ ìŠ¤",
          "feature7": "ë¬´ì œí•œ ë¹ ë¥¸ ëª¨ë¸",
          "feature8": "ê´‘ê³  ì—†ìŒ",
          "feature9": "í¬ë ˆë”§ì€ ì´ì›”ë˜ë©° ë§Œë£Œë˜ì§€ ì•ŠìŒ"
        }
      },
      "plan3": {
        "name": "í”„ë¦¬ë¯¸ì—„ í”Œëœ",
        "description": "ë” ë§ì€ ê¸°ëŠ¥ì´ í•„ìš”í•¨",
        "features": {
          "feature1": "í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸° ë¬´ë£Œ",
          "feature2": "ëª¨ë“  AI ëª¨ë¸ ì ‘ê·¼",
          "feature3": "ë¹„ë””ì˜¤ ë¬´ì œí•œ ì‚¬ìš© ğŸ”¥",
          "feature4": "ì—°ê°„ ìš”ê¸ˆìœ¼ë¡œ ëª¨ë“  í¬ë ˆë”§ì„ í•œ ë²ˆì— ë°›ê¸°",
          "feature5": "ë¹„ë””ì˜¤ íˆìŠ¤í† ë¦¬",
          "feature6": "ìƒì—…ìš© ë¼ì´ì„ ìŠ¤",
          "feature7": "ë¬´ì œí•œ ë¹ ë¥¸ ëª¨ë¸",
          "feature8": "ê´‘ê³  ì—†ìŒ",
          "feature9": "í¬ë ˆë”§ì€ ì´ì›”ë˜ë©° ë§Œë£Œë˜ì§€ ì•ŠìŒ"
        }
      },
      "plan4": {
        "name": "ê³ ê¸‰ í”Œëœ",
        "description": "ë” ë§ì€ ê¸°ëŠ¥ì´ í•„ìš”í•¨",
        "features": {
          "feature1": "í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸° ë¬´ë£Œ",
          "feature2": "ëª¨ë“  AI ëª¨ë¸ ì ‘ê·¼",
          "feature3": "ë¹„ë””ì˜¤ ë¬´ì œí•œ ì‚¬ìš© ğŸ”¥",
          "feature4": "ì—°ê°„ ìš”ê¸ˆìœ¼ë¡œ ëª¨ë“  í¬ë ˆë”§ì„ í•œ ë²ˆì— ë°›ê¸°",
          "feature5": "ë¹„ë””ì˜¤ íˆìŠ¤í† ë¦¬",
          "feature6": "ìƒì—…ìš© ë¼ì´ì„ ìŠ¤",
          "feature7": "ë¬´ì œí•œ ë¹ ë¥¸ ëª¨ë¸",
          "feature8": "ê´‘ê³  ì—†ìŒ",
          "feature9": "í¬ë ˆë”§ì€ ì´ì›”ë˜ë©° ë§Œë£Œë˜ì§€ ì•ŠìŒ"
        }
      }
    }
  },
  "refundPolicy": {
    "title": "Refund Policy",
    "description": "At ArtAny AI, we are committed to providing an exceptional experience for our users. We understand that circumstances may change, and you may need to request a refund. Please read our refund policy carefully before making a purchase.",
    "refundEligibility": {
      "title": "Refund Eligibility",
      "description": "Time Limit: ",
      "timeLimit": "Refund requests must be made within 3 days of your purchase. After this period, we will be unable to process any refund requests.",
      "creditUsage": "Credit Usage: ",
      "creditUsageDescription": "If you have used more than 100 credits, regardless of the purchase date, you will no longer be eligible for a refund."
    },
    "howToRequest": {
      "title": "How to Request a Refund",
      "description": "If you meet the above eligibility criteria and wish to request a refund, please follow these steps:",
      "contactUs": "Contact Us: ",
      "contactUsDescription": "Reach out to our support team via email at ",
      "contactUsLink": "help@artany.ai",
      "provideDetails": "Provide Details: ",
      "provideDetailsDescription": "Include your account information, order number, purchase date, and the reason for your refund request in the email.",
      "submitOnTime": "Submit on Time: ",
      "submitOnTimeDescription": "Ensure your refund request is submitted within 3 days of purchase."
    },
    "refundProcessing": {
      "title": "Refund Processing",
      "description": "Once we receive your refund request, we will review it and notify you of the result as soon as possible. If approved, the refund will be processed through your original payment method."
    },
    "policyChanges": {
      "title": "Policy Changes",
      "description": "We reserve the right to update the refund policy at any time. Any changes will be posted on this page, and we recommend checking regularly for the latest information."
    }
  },
  "text2video": {
    "title": "ì•„íŠ¸ ë¹„ë””ì˜¤ ìƒì„±ê¸°: í…ìŠ¤íŠ¸ì—ì„œ ë¹„ë””ì˜¤ë¡œ | ArtAny AI Video",
    "description": "Art AI í…ìŠ¤íŠ¸ì—ì„œ ë¹„ë””ì˜¤ë¡œ â€“ AIë¡œ í…ìŠ¤íŠ¸ë¥¼ í”„ë¡œê¸‰ í’ˆì§ˆì˜ ë¹„ë””ì˜¤ë¡œ ì¦‰ì‹œ ë³€í™˜. ìŠ¤ë§ˆíŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ ì†Œì…œ ë¯¸ë””ì–´ì™€ ë¹„ì¦ˆë‹ˆìŠ¤ì— ì™„ë²½í•œ í´ë¦½ ìƒì„±. ArtAny AI"
  },
  "wan-vace": {
    "title": "Wan 2.1 VACE: ì˜¤í”ˆì†ŒìŠ¤ ë¹„ë””ì˜¤ ìƒì„± ëª¨ë¸ | Wan VACE",
    "description": "Wan AI VACEëŠ” ì‹œì‘ ë° ì¢…ë£Œ í”„ë ˆì„ì—ì„œ HD ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•˜ëŠ” 14B ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ë¡œ, ì°½ì˜ì  ë° ìƒì—…ì  ì‚¬ìš©ì— ì´ìƒì ì…ë‹ˆë‹¤. Seedance AI Video Generation"
  },
  "wan-ai": {
    "title": "Wan AI Video Generation Model (Wan 2.1)| ArtAny AI",
    "description": "ArtAny AI integrates Wan AI video models, featuring Wan 2.1! Generate anime, realistic & 3D videos effortlessly. Perfect for creators and businesses. "
  },
  "image2video": {
    "title": "Art AI ì´ë¯¸ì§€ì—ì„œ ë¹„ë””ì˜¤ë¡œ, ì´ë¯¸ì§€ì—ì„œ ë¹„ë””ì˜¤ ìƒì„± | ArtAny",
    "description": "ArtAny AIì˜ ì´ë¯¸ì§€ì—ì„œ ë¹„ë””ì˜¤ë¡œ ë„êµ¬ëŠ” AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì™€ í”„ë¡¬í”„íŠ¸ì—ì„œ ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ë§ˆì¼€íŒ…, ì†Œì…œ ë¯¸ë””ì–´, ê°œì¸ í”„ë¡œì íŠ¸ì— ì´ìƒì . ì§€ê¸ˆ ì‹œë„í•´ë³´ì„¸ìš”!"
  },
  "videoEffects": {
    "title": "ë¹„ë””ì˜¤ìš© AI íš¨ê³¼ - ë¬´ë£Œ AI ë¹„ë””ì˜¤ í…œí”Œë¦¿ | ArtAny AI",
    "description": "ArtAny AIì—ì„œ 40ê°œ ì´ìƒì˜ ë¬´ë£Œ AI ë¹„ë””ì˜¤ íš¨ê³¼ì™€ í…œí”Œë¦¿ì„ ë°œê²¬í•˜ì„¸ìš”! ìµœì²¨ë‹¨ AI ê¸°ìˆ ë¡œ ë©‹ì§„ ë¹„ë””ì˜¤ë¥¼ ì†ì‰½ê²Œ ì œì‘. ì§€ê¸ˆ ì‹œë„í•´ë³´ì„¸ìš”!"
  },
  "veo3": {
    "title": "Google Veo3 AI ë¹„ë””ì˜¤ ìƒì„±ê¸°: í…ìŠ¤íŠ¸ì—ì„œ ë¹„ë””ì˜¤ë¡œ | ArtAny AI",
    "description": "Veo 3ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ê°€ ë™ê¸°í™”ëœ ë©‹ì§„ AI ë¹„ë””ì˜¤ë¥¼ ì œì‘í•˜ì„¸ìš”. ìŒí–¥ íš¨ê³¼, ëŒ€í™”, ì£¼ë³€ ì†ŒìŒì„ ì¶”ê°€í•˜ëŠ” ìµœì‹  AI ë¹„ë””ì˜¤ ìƒì„± ë„êµ¬ì…ë‹ˆë‹¤."
  },
  "models": {
    "wan-ai": {
      "title": "Wan 2.1: Leading AI Video Generation Model (Wanx 2.1)|Wan AI",
      "description": "Wan 2.1 (Alibaba WanX AI) an AI creative platform,enables text-to-image, image editing, text-to-video, video-to-video and image-to-video creation powered by AI.",
      "h1": "Wan 2.1 (Wanx 2.1) by Alibaba Wan AI",
      "h1-description": "Wan AI is an advanced and powerful visual generation model developed by Tongyi Lab. It can generate videos based on text, images and other control signals. The Wan 2.1 series models are now fully open-source.",
      "h2-1": "Overview of Wan AI",
      "h2-1-h3-1": "SOTA Performance",
      "h2-1-h3-1-description": "Wan 2.1 consistently outperforms existing open-source models and state-of-the-art commercial solutions across multiple benchmarks.",
      "h2-1-h3-2": "Supports Consumer-grade GPUs",
      "h2-1-h3-2-description": "The T2V-1.3B model requires only 8.19 GB VRAM, making it compatible with almost all consumer-grade GPUs. It can generate a 5-second 480P video on an RTX 4090 in about 4 minutes (without optimization techniques like quantization). Its performance is even comparable to some closed-source models.",
      "h2-1-h3-3": "Multiple tasks",
      "h2-1-h3-3-description": "Wan 2.1 excels in Text-to-Video, Image-to-Video, Video Editing, Text-to-Image, and Video-to-Audio, advancing the field of video generation.",
      "h2-1-h3-4": "Visual Text Generation",
      "h2-1-h3-4-description": "Wan 2.1 is the first video model capable of generating both Chinese and English text, featuring robust text generation that enhances its practical applications.",
      "h2-1-h3-5": "Powerful Video VAE of Wan AI",
      "h2-1-h3-5-description": "Wan-VAE delivers exceptional efficiency and performance, encoding and decoding 1080P videos of any length while preserving temporal information, making it an ideal foundation for video and image generation.",
      "h2-2": "Features of Wan AI",
      "h2-2-h3-1": "Complex Motions by Wan AI 2.1",
      "h2-2-h3-1-description": "Excels at generating realistic videos featuring extensive body movements, complex rotations, dynamic scene transitions, and fluid camera motions.",
      "h2-2-h3-2": "Physical Simulation by Wan AI 2.1",
      "h2-2-h3-2-description": "Generates videos that accurately simulate real-world physics and realistic object interactions.",
      "h2-2-h3-3": "Cinematic Quality by Wan AI 2.1",
      "h2-2-h3-3-description": "Offers movie-like visuals with rich textures and a variety of stylized effects.",
      "h2-2-h3-4": "Controllable Editing by Wan AI 2.1",
      "h2-2-h3-4-description": "Features a universal editing model for precise edits using image or video references.",
      "h2-2-h3-5": "Visual Text Generation by Wan AI 2.1",
      "h2-2-h3-5-description": "Creates text and dynamic text effects in videos directly from text prompts.",
      "h2-3": "Product Features",
      "h2-3-description": "Through our product, you can seamlessly leverage our models with a user-friendly experience to access inspiring video content.",
      "h2-3-h3-1": "Text to Video",
      "h2-3-h3-2": "Image to Video",
      "h2-3-h3-3": "Start and End Frames",
      "h2-4": "Wan AI 2.1 Open Source",
      "h2-4-description": "In this repo, we release the code and weights for the Wan 2.1, a comprehensive and open suite of video foundation models designed to push the boundaries of video generation.",
      "h2-4-h3-1": "Wan2.1-I2V-14B",
      "h2-4-h3-1-720P": "https://huggingface.co/Wan-AI/Wan2.1-I2V-14B-720P?spm=5176.28735610.0.0.568be41ehS0jcL&file=Wan2.1-I2V-14B-720P",
      "h2-4-h3-1-480P": "https://huggingface.co/Wan-AI/Wan2.1-I2V-14B-480P?spm=5176.28735610.0.0.568be41ehS0jcL&file=Wan2.1-I2V-14B-480P",
      "h2-4-h3-1-description": "The I2V-14B model outperforms leading closed-source models as well as all existing open-source models, achieving SOTA performance. It is capable of generating videos that demonstrate complex visual scenes and motion patterns based on input text and images, including both 480P and 720P resolution models.",
      "h2-4-h3-2": "Wan2.1-T2V-14B",
      "h2-4-h3-2-720P": "https://huggingface.co/Wan-AI/Wan2.1-T2V-14B?spm=5176.28735610.0.0.568be41ehS0jcL&file=Wan2.1-T2V-14B",
      "h2-4-h3-2-description": "The T2V-14B model sets a new SOTA performance among both open-source and closed-source models, showcasing its ability to generate high-quality visuals with substantial motion dynamics. It is also the only video model capable of producing both Chinese and English text and supports video generation at both 480P and 720P resolutions.",
      "h2-4-h3-3": "Wan2.1-T2V-1.3B",
      "h2-4-h3-3-480P": "https://huggingface.co/Wan-AI/Wan2.1-T2V-1.3B?spm=5176.28735610.0.0.568be41ehS0jcL&file=Wan2.1-T2V-1.3B",
      "h2-4-h3-3-description": "The T2V-1.3B model supports video generation on almost all consumer-grade GPUs, requiring only 8.19 GB of BRAM to produce a 5-second 480P video, with an output time of just 4 minutes on an RTX 4090 GPU. Through pre-training and distillation processes, it surpasses larger open-source models and achieves performance even comparable to some advanced closed-source models.",
      "h2-4-h3-4": "Wan2.1-FLF2V-14B-720P",
      "h2-4-h3-4-720P": "https://huggingface.co/Wan-AI/Wan2.1-FLF2V-14B-720P#run-first-last-frame-to-video-generation",
      "h2-4-h3-4-description": "Wan 2.1 First-Last-Frame-to-Video (FLF2V) is an AI-based video generation technology that synthesizes intermediate frames between a given start and end frame to produce smooth videos. It leverages a 14B-parameter model, supports multi-GPU accelerated inference, and offers pretrained checkpoints with a Gradio demo for interactive testing. Applications include video inpainting, animation production, and more.",
      "h2-5": "Frequently Asked Questions",
      "h2-5-h3-1": "What is Wan 2.1 by Wan AI and how does it work?",
      "h2-5-h3-1-description": "Wan 2.1 by Wan AI is Alibaba Cloud's state-of-the-art video generation model that transforms text descriptions into stunning, high-quality videos. Leveraging advanced technologies like Variational Autoencoders (VAE) and Diffusion Transformers (DiT), it ensures realistic visuals, smooth transitions, and accurate physics for a truly immersive experience.",
      "h2-5-h3-2": "Do I need technical expertise to use Wan 2.1 by Wan AI?",
      "h2-5-h3-2-description": "Wan 2.1 by Wan AI is designed with simplicity in mind. Its intuitive interface allows anyone to create professional-quality videos effortlessly, even without advanced technical skills. Whether you're a beginner or a pro, you'll find the platform easy to navigate and use.",
      "h2-5-h3-3": "What types of videos can I create with Wan 2.1 by Wan AI?",
      "h2-5-h3-3-description": "Wan 2.1 by Wan AI is versatile and capable of generating a wide range of video content. From dynamic scenes like dancing and sports to educational tutorials and historical video restoration, it empowers you to bring your creative vision to life.",
      "h2-5-h3-4": "How long does it take to generate a video?",
      "h2-5-h3-4-description": "The video generation time depends on the complexity and length of your project. For faster results, the Pro version offers accelerated processing speeds, making it ideal for time-sensitive tasks.",
      "h2-5-h3-5": "Can I customize the video output?",
      "h2-5-h3-5-description": "Absolutely! Wan 2.1 by Wan AI provides extensive customization options, allowing you to adjust resolution, frame rate, movement complexity, and more. Tailor your videos to meet your specific needs and preferences.",
      "h2-5-h3-6": "What input formats does Wan 2.1 AI by Wan AI support for video generation?",
      "h2-5-h3-6-description": "Wan 2.1 AI by Wan AI primarily supports text descriptions as input for video generation. You can provide detailed textual prompts describing the scene, actions, and desired visual effects. Additionally, it may support image inputs for enhanced context in future updates.",
      "h2-5-h3-7": "Can Wan 2.1 AI by Wan AI generate videos in multiple languages?",
      "h2-5-h3-7-description": "Yes, Wan 2.1 AI by Wan AI supports multilingual text inputs, allowing you to generate videos based on descriptions in various languages. However, the quality of output may vary depending on the language and the complexity of the description.",
      "h2-5-h3-8": "Is there a limit to the length of videos that Wan 2.1 by Wan AI can generate?",
      "h2-5-h3-8-description": "The length of generated videos depends on the subscription plan. The free version may have limitations on video duration, while the Pro version supports longer and more complex video generation. Specific limits can be found in the platform's documentation.",
      "h2-5-h3-9": "How does Wan 2.1 by Wan AI ensure the quality of generated videos?",
      "h2-5-h3-9-description": "Wan 2.1 AI by Wan AI leverages advanced technologies like Variational Autoencoders (VAE) and Diffusion Transformers (DiT) to ensure high-quality outputs. These technologies enable realistic visuals, smooth transitions, and accurate physics simulations.",
      "h2-5-h3-10": "How does Wan 2.1 by Wan AI handle complex scenes with multiple characters?",
      "h2-5-h3-10-description": "Wan 2.1 by Wan AI is designed to handle complex scenes with multiple characters by analyzing the relationships and interactions described in the text input. It uses advanced algorithms to ensure realistic positioning, movements, and interactions between characters."
    },
    "flux1": {
      "title": "ALL the Top-Tier AI Video Models in ONE Place | ArtAny AI",
      "description": "Create pro videos at low cost! ArtAny combines all AI video models - image-to-video, video-to-video, effects & images made easy. Use ArtAny AI video generator !"
    }
  },
  "imageGenerator": {
    "title": "ë¬´ë£Œ AI ì´ë¯¸ì§€ ìƒì„±ê¸° | ì•„íŠ¸ ì´ë¯¸ì§€ | ArtAny AI Image",
    "description": "ArtAny AI - ì¸ê¸° ëª¨ë¸ì´ íƒ‘ì¬ëœ 100% ë¬´ë£Œ ë° ë¬´ì œí•œ AI ì´ë¯¸ì§€ ìƒì„±ê¸°â€”ì›í´ë¦­ìœ¼ë¡œ ê³ í’ˆì§ˆ ë¹„ì£¼ì–¼ ì œì‘! | ArtAny AI"
  },
  "flux1Kontext": {
    "title": "Flux1 Kontext Pro, Max, ë©€í‹° ì´ë¯¸ì§€ â€“ ArtAny AIì—ì„œ Flux1 ì²´í—˜í•˜ê¸°",
    "description": "Flux.1 Kontextë¡œ ë©€í‹° ì´ë¯¸ì§€ í”„ë¡œì íŠ¸ë¥¼ ì‰½ê²Œ ìƒì„±í•˜ê³  í¸ì§‘í•˜ì„¸ìš”. ë³µì¡í•œ ì‘ì—…ì„ ì†ì‰½ê²Œ! ArtAny AIì—ì„œ Flux Pro, Max & Multië¥¼ ì§€ê¸ˆ ì²´í—˜í•´ë³´ì„¸ìš”!"
  },
  "homeShow": {
    "title": "Free AI Video Prompt Generator - AI Image Prompt Generator",
    "description": "the best prompt generator for AI video and image generation, Wan AI, Flux1, Runway, Veo3, Kling AI, Seedance1.0, Google, ByteDance, ArtAny AI"
  },
  "explore": {
    "title": "AI Videos: Discover Free AI-generated Videos | ArtAny",
    "description": "Find high-quality videos generated by AI. Create stunning AI videos using the same template."
  },
  "prompt": {
    "SEO": {
      "title": "Free AI Video Prompt Generator - Perfect Prompts for AI Model",
      "description": "Free prompt tool for AI! Generate prompts for image-to-video,text-to-video & text-to-image.Perfect for Wan AI, Flux, Runway.Ideal for creators & developers.",
      "keywords": "AI Prompt Generator Tool"
    },
    "promptGenerator": {
      "name": "Video Prompt Generator",
      "description": "Select prompt formula",
      "viewTutorial": "View tutorial",
      "selectFormula": "Select formula",
      "formulas": {
        "basic": {
          "name": "Basic Formula",
          "description": "Suitable for new users trying AI video for the first time"
        },
        "advanced": {
          "name": "Advanced Formula",
          "description": "Suitable for users with some AI video experience"
        },
        "camera": {
          "name": "Camera Movement Formula",
          "description": "Suitable for users with specific camera movement requirements"
        },
        "transformation": {
          "name": "Transformation Formula",
          "description": "Suitable for users who need transformation effects"
        }
      },
      "selectOutputLanguage": "Select output language",
      "enterYourIdea": "Enter your idea",
      "enterYourIdeaDescription": "Describe the video content you want to generate...",
      "loginForFreeAccess": "Login for free access",
      "generatePrompt": "Generate Prompt",
      "generating": "Generating...",
      "resultName": "Generated Result",
      "copied": "Copied",
      "copy": "Copy",
      "generatingPrompt": "Generating prompt, please wait...",
      "resultDescription": "Enter your idea on the left and generate a prompt.",
      "exploreMore": "Explore more"
    },
    "title": "How to write and debug AI prompts",
    "description": "We provide a powerful free prompt generator that helps users generate high-quality prompts, making it easier to use Wan AI and other AI video generation tools.",
    "target": "Target audience",
    "feature": "Features",
    "example": "Example prompts",
    "optionalTargetType": "Optional target type",
    "notRecommended": "Not recommended",
    "recommended": "Recommended",
    "initialPrompt": "Initial prompt",
    "exampleCombination": "Example combination",
    "adjustedPrompt": "Adjusted prompt",
    "combination1": "Combination 1",
    "combination2": "Combination 2",
    "recommendedOperation": "Recommended operation",
    "section1": {
      "title": "How to use the prompt generator",
      "modes": {
        "basic": {
          "name": "Basic mode (Basic Formula)",
          "target": "New users trying AI video for the first time",
          "feature": "Provides simple and easy-to-understand prompt templates, suitable for quick start",
          "example": "Beach, sunset, waves"
        },
        "advanced": {
          "name": "Advanced mode (Advanced Formula)",
          "target": "Users with some AI video generation experience",
          "feature": "Supports more complex prompt combinations, generating more creative videos",
          "example": "Future city, flying car, neon lights"
        },
        "camera": {
          "name": "Camera movement mode (Camera Movement Formula)",
          "target": "Users with specific camera movement requirements",
          "feature": "Supports adding camera movement effects, such as panning, zooming, and rotating",
          "example": "Mountain range, sunrise, panning"
        },
        "transformation": {
          "name": "Transformation mode (Transformation Formula)",
          "target": "Users who need to generate transformation effects",
          "feature": "Supports generating transformation effects of objects or scenes, such as gradual change and fusion",
          "example": "Flower, bloom, transformation"
        }
      }
    },
    "section2": {
      "title": "How to write AI prompts",
      "tips": {
        "clearGoal": {
          "title": "Clear goal",
          "description": "Before writing AI prompts, clearly define the video content you want to generate. The clearer your goal, the better the generated video will be.",
          "example1": "Landscape video",
          "example2": "Character close-up",
          "example3": "Dynamic effect"
        },
        "simpleLanguage": {
          "title": "Use simple language",
          "description": "AI prompts should be concise and clear, avoiding complex sentences.",
          "badExample": "Generate a video of children playing in the park in the afternoon.",
          "goodExample": "Sunny afternoon, children, park, play"
        },
        "keywordCombination": {
          "title": "Keyword combination",
          "description": "Combine multiple keywords to generate more diverse video content.",
          "example": "Sunset, beach, waves, coconut tree"
        },
        "styleEmotion": {
          "title": "Add style or emotion",
          "description": "If you need a specific style or emotion, you can add related descriptions in the AI prompt.",
          "example": "Romantic, sunset, couple, walk"
        }
      }
    },
    "section3": {
      "title": "How to debug AI prompts",
      "tips": {
        "stepByStep": {
          "title": "Step by step",
          "description": "If the generated video is not satisfactory, you can adjust the AI prompt step by step.",
          "initialPrompt": "City, night view",
          "adjustedPrompt": "City, night view, light, traffic"
        },
        "testCombinations": {
          "title": "Test different combinations",
          "description": "Try different keyword combinations to find the best effect.",
          "combination1": "Forest, morning mist, sunshine",
          "combination2": "Forest, morning mist, bird song"
        },
        "reference": {
          "title": "Reference template",
          "description": "Reference our provided prompts and AI video templates, quick start.",
          "item1": "Browse template library",
          "item2": "Reference popular prompts",
          "item3": "Learn success cases",
          "link1": "View detailed tutorial",
          "link2": "View template samples"
        }
      }
    }
  },
  "Creator": {
    "title": "Portfolio",
    "description": "A collection of works by ArtAny creators.",
    "keywords": "ArtAny creators, ArtAny portfolio, ArtAny artworks, ArtAny creator works"
  }
}